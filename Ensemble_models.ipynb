{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from utils import update_submission\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bagging (sampling with replacement)\n",
    "   100 samples, randomly choose 60 out of 100, load them to Tree 1.\n",
    "   Put the 60 back, resample 60, load the new 60 samples to Tree 2.\n",
    "   ...\n",
    "   Tree N.\n",
    "2. Max_feature:\n",
    "   Each split on the tree is based on one feature, each tree will have different features, maxed at Max_feature\n",
    "When making predictions, all the trees will vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/test.csv')\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_submission = pd.read_csv('./data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df,option):\n",
    "    assert option in [\"test\",\"train\"] , \"Option must be test or train\"\n",
    "    df = df.set_index('PassengerId')\n",
    "    cond = df.Fare.isnull()\n",
    "    sub_value = df.Fare.mean()\n",
    "    df.Fare = np.where(cond, sub_value, df.Fare)\n",
    "    ticket_p = df.groupby('Ticket', as_index=False).agg({'Name': 'count'}).rename(columns={'Name':'t_count'}).sort_values('t_count', ascending=False)\n",
    "    d = dict()\n",
    "    for i, row in ticket_p.iterrows():\n",
    "        d[row.Ticket] = row.t_count\n",
    "    df_merge = df.copy()\n",
    "    df_merge['t_count'] = df_merge.Ticket.apply(lambda x: d[x])\n",
    "    df_merge['Fare_per_person'] = df_merge.Fare/df_merge.t_count\n",
    "    cond = df_merge.Age.isnull()\n",
    "    sub_value = df_merge.Age.mean()\n",
    "    df_merge.Age = np.where(cond, sub_value, df_merge.Age)\n",
    "    cond = (df_merge.Sex == 'female')\n",
    "    sub_value = 1\n",
    "    df_merge.Sex = np.where(cond, sub_value, 0)\n",
    "    cond = df_merge.Embarked.isnull()\n",
    "    sub_value = 'S'\n",
    "    df_merge.Embarked = np.where(cond, 'S', df_merge.Embarked)\n",
    "    df_merge = df_merge.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    df_merge.isnull().sum()\n",
    "    ohe = OneHotEncoder()\n",
    "    X_cat = ohe.fit_transform(df_merge.Embarked.values.reshape(-1,1)).toarray()\n",
    "    if option==\"train\":\n",
    "        X_short = df_merge.drop(['Survived','Embarked'], axis=1).values\n",
    "    else:\n",
    "        X_short = df_merge.drop(['Embarked'], axis=1).values\n",
    "    X = np.hstack([X_cat, X_short])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = transform(df_train, \"train\")\n",
    "X_test = transform(df_test,\"test\")\n",
    "y_train_val = df_train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': array([2, 3, 4]),\n",
       "                         'max_features': array([2, 4, 6, 8]),\n",
       "                         'min_samples_leaf': array([ 1,  6, 11, 16]),\n",
       "                         'min_samples_split': array([10, 15, 20, 25]),\n",
       "                         'n_estimators': [50, 150, 250]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators': [50,150,250],\n",
    "              'max_depth': np.arange(2,5),\n",
    "              'min_samples_split': np.arange(10,30,5),\n",
    "              'min_samples_leaf': np.arange(1,10,2),\n",
    "              'max_features': np.arange(2,10,2)}\n",
    "gs = GridSearchCV(rf, param_grid, scoring='accuracy', n_jobs=-1, refit=True, cv=5)\n",
    "gs.fit(X_train_val,y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 8,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815956311593748"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gs.predict(X_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=sklearn.metrics.confusion_matrix(y_train_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428731762065096"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[0][0]+cm[1][1])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'n_estimators': [50, 100, 150, ...], # 3\n",
    "#               'max_depth': np.arange(4,10), # 6\n",
    "#               'min_samples_split': np.arange(10,20,2), # 5\n",
    "#               'min_samples_leaf': np.arange(1,10,2), # 5\n",
    "#               'max_features': ?????} # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW (Jan 12. 2021):\n",
    "# 1. to fine tune our RandomForestClassifier and get a accuracy > 82%.\n",
    "# 2. read about (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) \n",
    "#    print the confusion matrix of your model on the whole train_val set\n",
    "# 3. update the submission file with the function in utils.py, submit it to kaggle, compare the result with\n",
    "# what we get locally (CV)\n",
    "# 4. Read about https://www.youtube.com/watch?v=bfmFfD2RIcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3*6*5*5*3 --> 50 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "cross_val_score(gb, X_train_val, y_train_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type I error (false positive):\n",
    "model says positive, actually negative (COVID)\n",
    "Type II error (false negative):\n",
    "model says negative, actually positive (COVID)\n",
    "\n",
    "Type II error more harmful than Type I error\n",
    "\n",
    "100 person, 50/50 (COVID/HC)\n",
    "\n",
    "model 1 (simply classifies every person to have COVID):\n",
    "accuracy: 50%\n",
    "Type II: 0\n",
    "\n",
    "model 2:\n",
    "50 COVID: 30 correct, 20 wrong\n",
    "50 HC: 50 correct, 0 wrong\n",
    "accuracy: 80%\n",
    "Type II: 20\n",
    "\n",
    "model 3:\n",
    "50 COVID: 45 correct, 5 wrong\n",
    "50 HC: 25 correct, 25 wrong\n",
    "accuracy: 70%\n",
    "Type II: 5\n",
    "\n",
    "confusion matrix:\n",
    "           model 1      model 0\n",
    "true 1        50           0\n",
    "true 0        50           0\n",
    "\n",
    "real life COST for mistakes:\n",
    "(domain knowledge) \n",
    "\n",
    "COVID\n",
    "Type II 100 bucks\n",
    "Type I 1 buck\n",
    "model 1 cost: 50 bucks\n",
    "model 2 cost: 2000 bucks\n",
    "model 3 cost: 525 bucks\n",
    "\n",
    "FLU\n",
    "Type II 5 bucks\n",
    "Type I 1 buck\n",
    "model 1 cost: 50 bucks\n",
    "model 2 cost: 100 bucks\n",
    "model 3 cost: 50 bucks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
